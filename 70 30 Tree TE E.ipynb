{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aim: To observe the relation (if any) between entropy and training error.\n",
    "## 70-30 Division\n",
    "\n",
    "\n",
    "## Results:\n",
    "- Entropy of y = 0.8849272200994921\n",
    "- T.E. = 0.14249999999999996\n",
    "- training accuracy score = 0.8575\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14249999999999996\n"
     ]
    }
   ],
   "source": [
    "t_e = 1 - 0.8575\n",
    "print(t_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps followed:\n",
    "\n",
    "1. Generating a random dataset\n",
    "2. Split dataset\n",
    "3. Train decision tree classifier, criterion = 'entropy'\n",
    "4. Check the outputs for entropy and training error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1 Characteristics:\n",
    "- Number of samples: 1000\n",
    "- 70/30 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from pyitlib import discrete_random_variable as drv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "# 70-30 classes\n",
    "X, y = make_classification(n_samples = 1000, n_features=2, n_classes = 2, n_redundant=0, n_informative=2, random_state = 9, weights = [0.7,0.3])\n",
    "# scatter plot, dots colored by class value\n",
    "d = {'x1':X[:,0], 'x2':X[:,1], 'y':y}\n",
    "df = DataFrame(data = d)\n",
    "colors = {0:'red', 1:'blue'}\n",
    "fig, ax = pyplot.subplots()\n",
    "grouped = df.groupby('y')\n",
    "for key, group in grouped:\n",
    "    group.plot(ax=ax, kind='scatter', x='x1', y='x2', label=key, color=colors[key])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method - 1\n",
    "Sklearn decision tree classifier\n",
    "Training error output (no entropy output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset to train, test\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training decision tree classifier\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=1, max_leaf_nodes=2)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8575"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train).score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8575]\n",
      "[0.855]\n"
     ]
    }
   ],
   "source": [
    "train_errors = list()\n",
    "test_errors = list()\n",
    "\n",
    "train_errors.append(clf.score(X_train, y_train))\n",
    "test_errors.append(clf.score(X_test, y_test))\n",
    "\n",
    "print(train_errors)\n",
    "print(test_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2\n",
    "- Has Entropy output (entropy of y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_and_accuracy(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "    classifier = DecisionTreeClassifier()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    print(\"Entropy\", drv.entropy(y))\n",
    "    #print(\"Accuracy \",accuracy_score(y_pred, y_test))\n",
    "    return(drv.entropy(y), accuracy_score(y_pred, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy 0.8849272200994921\n",
      "Entropy 0.8849272200994921\n",
      "Entropy 0.8849272200994921\n",
      "Entropy 0.8849272200994921\n",
      "Entropy 0.8849272200994921\n",
      "Entropy 0.8849272200994921\n",
      "Entropy 0.8849272200994921\n",
      "Entropy 0.8849272200994921\n",
      "Entropy 0.8849272200994921\n",
      "Entropy 0.8849272200994921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(0.88492722), 0.83),\n",
       " (array(0.88492722), 0.865),\n",
       " (array(0.88492722), 0.8),\n",
       " (array(0.88492722), 0.815),\n",
       " (array(0.88492722), 0.82),\n",
       " (array(0.88492722), 0.835),\n",
       " (array(0.88492722), 0.84),\n",
       " (array(0.88492722), 0.81),\n",
       " (array(0.88492722), 0.79),\n",
       " (array(0.88492722), 0.83)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_list = []\n",
    "for i in range(10):\n",
    "    acc_list.append(classify_and_accuracy(X,y))\n",
    "acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
